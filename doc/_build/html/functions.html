

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>RHIPE Functions &mdash; RHIPE v0.65.3 documentation</title>
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.65.3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="RHIPE v0.65.3 documentation" href="index.html" />
    <link rel="next" title="Packaging a Job for MapReduce" href="mr.html" />
    <link rel="prev" title="Simulations" href="simulate.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="mr.html" title="Packaging a Job for MapReduce"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="simulate.html" title="Simulations"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">RHIPE v0.65.3 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">RHIPE Functions</a><ul>
<li><a class="reference internal" href="#hdfs-related">HDFS Related</a><ul>
<li><a class="reference internal" href="#rhdel-file-deletion">rhdel - File Deletion</a></li>
<li><a class="reference internal" href="#rhls-listing-files">rhls - Listing Files</a></li>
<li><a class="reference internal" href="#rhget-copying-from-the-hdfs">rhget - Copying from the HDFS</a></li>
<li><a class="reference internal" href="#rhput-copying-to-the-hdf">rhput - Copying to the HDF</a></li>
<li><a class="reference internal" href="#rhcp-copying-on-the-hdfs">rhcp - Copying on the HDFS</a></li>
<li><a class="reference internal" href="#rhwrite-writing-r-data-to-the-hdfs">rhwrite - Writing R data to the HDFS</a></li>
<li><a class="reference internal" href="#rhread-reading-data-from-hdfs-into-r">rhread - Reading data from HDFS into R</a></li>
<li><a class="reference internal" href="#rhgetkeys-reading-values-from-map-files">rhgetkeys - Reading Values from Map Files</a></li>
<li><a class="reference internal" href="#rhstreamsequence-reading-from-a-sequence-file-in-a-streaming-fashion">rhstreamsequence - Reading from a sequence file in a streaming fashion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#mapreduce-administration">MapReduce Administration</a><ul>
<li><a class="reference internal" href="#rhex-submitting-a-mapreduce-r-object-to-hadoop">rhex - Submitting a MapReduce R Object to Hadoop</a></li>
<li><a class="reference internal" href="#rhstatus-monitoring-a-mapreduce-job">rhstatus - Monitoring a MapReduce Job</a></li>
<li><a class="reference internal" href="#rhjoin-waiting-on-completion-of-a-mapreduce-job">rhjoin - Waiting on Completion of a MapReduce Job</a></li>
<li><a class="reference internal" href="#rhkill-stopping-a-mapreduce-job">rhkill - Stopping a MapReduce Job</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="simulate.html"
                        title="previous chapter">Simulations</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="mr.html"
                        title="next chapter">Packaging a Job for MapReduce</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/functions.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="rhipe-functions">
<h1>RHIPE Functions<a class="headerlink" href="#rhipe-functions" title="Permalink to this headline">¶</a></h1>
<p>RHIPE has functions that access the HDFS from R, that are used inside MapReduce
jobs and functions for managing MapReduce jobs.</p>
<p>Before calling any of the functions described below, call <tt class="docutils literal"><span class="pre">rhinit</span></tt>. If you call <cite>rhinit(TRUE,TRUE,buglevel=2000)`</cite> a slew
of messages are displayed  - useful if Rhipe does not load.</p>
<div class="section" id="hdfs-related">
<h2>HDFS Related<a class="headerlink" href="#hdfs-related" title="Permalink to this headline">¶</a></h2>
<div class="section" id="rhdel-file-deletion">
<span id="index-0"></span><h3>rhdel - File Deletion<a class="headerlink" href="#rhdel-file-deletion" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhdel<span class="p">(</span>folders<span class="p">)</span>
</pre></div>
</div>
<p>This function deletes the folders contained in the character vector <tt class="docutils literal"><span class="pre">folders</span></tt>
which are located on the HDFS. The deletion is recursive, so all subfolders will
be deleted too. Nothing is returned.</p>
</div>
<div class="section" id="rhls-listing-files">
<span id="index-1"></span><h3>rhls - Listing Files<a class="headerlink" href="#rhls-listing-files" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhls<span class="p">(</span>path<span class="p">,</span> recurse<span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
</pre></div>
</div>
<p>Returns a data frame of filesystem information for the files located at <tt class="docutils literal"><span class="pre">path</span></tt>. If
<tt class="docutils literal"><span class="pre">recurse</span></tt> is TRUE, <tt class="docutils literal"><span class="pre">rhls</span></tt> will recursively travel the directory tree
rooted at <tt class="docutils literal"><span class="pre">path</span></tt>. The returned object is a data frame consisting of the
columns: <em>permission, owner, group, size (which is numeric), modification time</em>,
and the <em>file name</em>. <tt class="docutils literal"><span class="pre">path</span></tt> may optionally <strong>end</strong> in &#8216;*&#8217; which is the
wildcard and will match any character(s).</p>
</div>
<div class="section" id="rhget-copying-from-the-hdfs">
<span id="index-2"></span><h3>rhget - Copying from the HDFS<a class="headerlink" href="#rhget-copying-from-the-hdfs" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhget<span class="p">(</span>src<span class="p">,</span>dest<span class="p">)</span>
</pre></div>
</div>
<p>Copies the files (or folder) at <tt class="docutils literal"><span class="pre">src</span></tt>, located on the HDFS to the
destination <tt class="docutils literal"><span class="pre">dest</span></tt> located on the local filesystem. If a file or folder of
the same name as <tt class="docutils literal"><span class="pre">dest</span></tt> exists on the local filesystem, it will be
deleted. The <tt class="docutils literal"><span class="pre">dest</span></tt> can contain &#8220;~&#8221; which will be expanded.</p>
</div>
<div class="section" id="rhput-copying-to-the-hdf">
<span id="index-3"></span><h3>rhput - Copying to the HDF<a class="headerlink" href="#rhput-copying-to-the-hdf" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhput<span class="p">(</span>src<span class="p">,</span>dest<span class="p">)</span>
</pre></div>
</div>
<p>Copies the local file called <tt class="docutils literal"><span class="pre">src</span></tt> (not a folder) to the destination <tt class="docutils literal"><span class="pre">dest</span></tt>
on the HDFS. Uses <tt class="docutils literal"><span class="pre">path.expand</span></tt> to expand the <tt class="docutils literal"><span class="pre">src</span></tt> parameter.</p>
</div>
<div class="section" id="rhcp-copying-on-the-hdfs">
<span id="index-4"></span><h3>rhcp - Copying on the HDFS<a class="headerlink" href="#rhcp-copying-on-the-hdfs" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhcp<span class="p">(</span>src<span class="p">,</span>dest<span class="p">)</span>
</pre></div>
</div>
<p>Copies the file (or folder) <tt class="docutils literal"><span class="pre">src</span></tt> on the HDFS to the destination <tt class="docutils literal"><span class="pre">dest</span></tt>
also on the HDFS.</p>
</div>
<div class="section" id="rhwrite-writing-r-data-to-the-hdfs">
<span id="index-5"></span><h3>rhwrite - Writing R data to the HDFS<a class="headerlink" href="#rhwrite-writing-r-data-to-the-hdfs" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhwrite<span class="p">(</span>list<span class="p">,</span>dest<span class="p">,</span>N<span class="o">=</span><span class="kc">NULL</span><span class="p">)</span>
</pre></div>
</div>
<p>Takes a list of objects, found in <tt class="docutils literal"><span class="pre">list</span></tt> and writes them to the folder pointed
to by <tt class="docutils literal"><span class="pre">dest</span></tt> which will be located on the HDFS. The file <tt class="docutils literal"><span class="pre">dest</span></tt> will be in a
format interpretable by RHIPE, i.e it can be used as input to a MapReduce job.
The values of the list of are written as key-value pairs in a SequenceFileFormat
format. <tt class="docutils literal"><span class="pre">N</span></tt> specifies the number of files to write the values to. For example,
if <tt class="docutils literal"><span class="pre">N</span></tt> is 1, the entire list <tt class="docutils literal"><span class="pre">list</span></tt> will be written to one file in the
folder <tt class="docutils literal"><span class="pre">dest</span></tt>. Computations across small files do not parallelize well on
Hadoop. If the file is small, it will be treated as one split and the user does
not gain any (hoped for) parallelization. Distinct files are treated as distinct
splits. It is better to split objects across a number of files. If the list
consists of a million objects, it is prudent to split them across a few
files. Thus if <img class="math" src="_images/math/fc97ef67268cd4e91bacdf12b8901d7036c9a056.png" alt="N"/> is 10 and <tt class="docutils literal"><span class="pre">list</span></tt> contains 1,000,000
values, each of the 10 files (located in the directory <tt class="docutils literal"><span class="pre">dest</span></tt>) will contain
100,000 values.</p>
<p>Since the list only contains values, the keys are the indices of the
value in the list, stored as strings. Thus when used as a source for a MapReduce
job, the variable <tt class="docutils literal"><span class="pre">map.keys</span></tt> will contain numbers in the range <img class="math" src="_images/math/0959116ddc7f986700bf252640d9a22417594f0c.png" alt="[1,
length(list)]"/>. The variable <tt class="docutils literal"><span class="pre">map.values</span></tt> will contain elements of
<tt class="docutils literal"><span class="pre">list</span></tt>.</p>
</div>
<div class="section" id="rhread-reading-data-from-hdfs-into-r">
<span id="index-6"></span><h3>rhread - Reading data from HDFS into R<a class="headerlink" href="#rhread-reading-data-from-hdfs-into-r" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhread<span class="p">(</span>files<span class="p">,</span>type<span class="o">=</span><span class="s">&quot;sequence&quot;</span><span class="p">,</span>max<span class="o">=</span><span class="m">-1</span><span class="p">,</span>mc<span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span>buffsize<span class="o">=</span><span class="m">2</span><span class="o">*</span><span class="m">1024</span><span class="o">*</span><span class="m">1024</span><span class="p">)</span>
</pre></div>
</div>
<p>Reads the key,value pairs from the files pointed to by <tt class="docutils literal"><span class="pre">files</span></tt>. The source
<tt class="docutils literal"><span class="pre">files</span></tt> can end in a wildcard (*) e.g. <em>/path/input/p*</em> will read all the
key,value pairs contained in files starting with <em>p</em> in the folder
<em>/path/input/</em>.  The parameter <tt class="docutils literal"><span class="pre">type</span></tt> specifies the format of <tt class="docutils literal"><span class="pre">files</span></tt>. This
can be one of <tt class="docutils literal"><span class="pre">text</span></tt>, <tt class="docutils literal"><span class="pre">map</span></tt> or <tt class="docutils literal"><span class="pre">sequence</span></tt> which imply a Text file, MapFile or a
SequenceFile respectively. For text files, RHIPE returns a matrix of lines, each row a line from the text files.
Specifying <tt class="docutils literal"><span class="pre">max</span></tt> for text files, limits the number of bytes read and is currently alpha quality.</p>
<blockquote>
<div>Thus data written by <tt class="docutils literal"><span class="pre">rhwrite</span></tt> can be read</div></blockquote>
<p>using <tt class="docutils literal"><span class="pre">rhread</span></tt>. The parameter <tt class="docutils literal"><span class="pre">max</span></tt> specifies the maximum number of entries
to read, by default all the key,value pairs will be read. Setting <tt class="docutils literal"><span class="pre">mc</span></tt> to TRUE
will use the the <tt class="docutils literal"><span class="pre">multicore</span></tt> <a class="reference internal" href="#multicore">[multicore]</a> package to convert the data to R
objects in parallel. The user must have first loaded <tt class="docutils literal"><span class="pre">multicore</span></tt> via call to
library. This often does accelerate the process of reading data into R.</p>
<table class="docutils citation" frame="void" id="multicore" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[multicore]</a></td><td><a class="reference external" href="http://http://cran.r-project.org/web/packages/multicore/index.html">http://http://cran.r-project.org/web/packages/multicore/index.html</a></td></tr>
</tbody>
</table>
<span class="target" id="index-7"></span></div>
<div class="section" id="rhgetkeys-reading-values-from-map-files">
<span id="index-8"></span><h3>rhgetkeys - Reading Values from Map Files<a class="headerlink" href="#rhgetkeys-reading-values-from-map-files" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhgetkey<span class="p">(</span>keys<span class="p">,</span> path<span class="p">)</span>
</pre></div>
</div>
<p>Returns the values from the map files contained in <tt class="docutils literal"><span class="pre">path</span></tt> corresponding to the
keys in <tt class="docutils literal"><span class="pre">keys</span></tt>. <tt class="docutils literal"><span class="pre">path</span></tt> will contain folders which is MapFiles are
stored. Thus the <tt class="docutils literal"><span class="pre">path</span></tt> must have been created as the output of a RHIPE job
with <tt class="docutils literal"><span class="pre">inout[2]</span></tt> (the output format) set to <em>map</em>. Also, the saved keys must be in sorted order. This is always the case if</p>
<ol class="arabic simple">
<li><em>mapred.reduce.tasks</em> is not zero.</li>
<li>The variable <em>reduce.key</em> is not modified.</li>
<li><tt class="docutils literal"><span class="pre">orderby</span></tt> is not the default (<em>bytes</em>) in the call to <tt class="docutils literal"><span class="pre">rhmr</span></tt></li>
</ol>
<p>A simple way to convert any RHIPE SequenceFile data set  to MapFile is to run an identity MapReduce</p>
<div class="highlight-r"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="highlight"><pre>map <span class="o">&lt;-</span> expression<span class="p">({</span>
  lapply<span class="p">(</span>seq_along<span class="p">(</span>map.values<span class="p">),</span><span class="kr">function</span><span class="p">(</span>i<span class="p">)</span>
    rhcollect<span class="p">(</span>map.keys<span class="p">[[</span>i<span class="p">]],</span>map.values<span class="p">[[</span>i<span class="p">]]))</span>
<span class="p">})</span>
rhmr<span class="p">(</span>map<span class="o">=</span>map<span class="p">,</span>ifolder<span class="p">,</span>ofolder<span class="p">,</span>inout<span class="o">=</span>c<span class="p">(</span><span class="s">&quot;sequence&quot;</span><span class="p">,</span><span class="s">&quot;map&quot;</span><span class="p">))</span>
</pre></div>
</td></tr></table></div>
<p>The <tt class="docutils literal"><span class="pre">keys</span></tt> argument is a list of the keys. Keys are R objects and are characterized by their attributes too. So</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> identical<span class="p">(</span>c<span class="p">(</span>x<span class="o">=</span><span class="m">1</span><span class="p">),</span>c<span class="p">(</span><span class="m">1</span><span class="p">))</span>
<span class="kc">FALSE</span>
</pre></div>
</div>
<p>If the stored key is <tt class="docutils literal"><span class="pre">c(x=1)</span></tt> then this call to <tt class="docutils literal"><span class="pre">rhgetkey</span></tt> will not work</p>
<div class="highlight-r"><div class="highlight"><pre>rhgetkey<span class="p">(</span>list<span class="p">(</span>c<span class="p">(</span><span class="m">1</span><span class="p">)),</span>path<span class="p">)</span>
</pre></div>
</div>
<p>but this will</p>
<div class="highlight-r"><div class="highlight"><pre>rhgetkey<span class="p">(</span>list<span class="p">(</span>c<span class="p">(</span>x<span class="o">=</span><span class="m">1</span><span class="p">)),</span>path<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="rhstreamsequence-reading-from-a-sequence-file-in-a-streaming-fashion">
<h3>rhstreamsequence - Reading from a sequence file in a streaming fashion<a class="headerlink" href="#rhstreamsequence-reading-from-a-sequence-file-in-a-streaming-fashion" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhstreamsequence<span class="p">(</span>inputfile<span class="p">,</span>type<span class="o">=</span><span class="s">&#39;sequence&#39;</span><span class="p">,</span>batch<span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="m">...</span><span class="p">)</span>
</pre></div>
</div>
<p><tt class="docutils literal"><span class="pre">rhread</span></tt> only reads from the beginning a prechosen number or all of the
data. This function enables the user to open a file and read in blocks till the
end of the file or all files in the folder specified by <tt class="docutils literal"><span class="pre">inputfile</span></tt> . The
function returns a list of two closures <tt class="docutils literal"><span class="pre">get</span></tt> and <tt class="docutils literal"><span class="pre">close</span></tt>. The former takes
one parameter <tt class="docutils literal"><span class="pre">mc</span></tt>. The <tt class="docutils literal"><span class="pre">mc</span></tt> option is given to the multi-core package to
deserialize in parallel. Call the <tt class="docutils literal"><span class="pre">close</span></tt> closure to close the file. Note, due
to a bug in the logic, the <tt class="docutils literal"><span class="pre">get</span></tt> function may retrieve from <tt class="docutils literal"><span class="pre">batch</span></tt> to
<tt class="docutils literal"><span class="pre">2*batch</span></tt> values.</p>
<div class="highlight-r"><div class="highlight"><pre>e <span class="o">&lt;-</span> rhstreamsequence<span class="p">(</span><span class="s">&quot;/tmp/x/0&quot;</span><span class="p">,</span>batch<span class="o">=</span><span class="m">100</span><span class="p">)</span>
a <span class="o">&lt;-</span> e<span class="p">$</span>get<span class="p">()</span>
a <span class="o">&lt;-</span> e<span class="p">$</span>get<span class="p">()</span> <span class="c1"># returns an empty list if reached end.</span>
e<span class="p">$</span>close<span class="p">()</span>
</pre></div>
</div>
<p>This is particularly useful for the <tt class="docutils literal"><span class="pre">biglm</span></tt> package which accepts a function
to return blocks of data (typically data frames). If your data source is stored
as key/value pairs where the values are data frames, you can use
<tt class="docutils literal"><span class="pre">rhbiglm.stream.hdfs</span></tt> to provide data to <tt class="docutils literal"><span class="pre">biglm</span></tt> as in</p>
<div class="highlight-r"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="highlight"><pre>modifier <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>df<span class="p">,</span>reset<span class="p">){</span>
  <span class="c1">## different chunks might not all display all the levels</span>
  <span class="c1">## of rm.site, so we have to predefine all levels visible</span>
  <span class="c1">## across data site</span>
  <span class="kr">if</span><span class="p">(</span>!reset<span class="p">){</span>
    total.rows<span class="o">&lt;&lt;-</span>total.rows<span class="o">+</span>nrow<span class="p">(</span>df<span class="p">)</span>
    cat<span class="p">(</span>sprintf<span class="p">(</span><span class="s">&quot;Total rows:%s\n&quot;</span><span class="p">,</span>total.rows<span class="p">))</span>
  <span class="p">}</span>else <span class="p">{</span>total.rows<span class="o">&lt;&lt;-</span><span class="m">0</span><span class="p">;</span><span class="kr">return</span><span class="p">()}</span>
  df<span class="p">$</span>rm.site <span class="o">&lt;-</span> factor<span class="p">(</span>df<span class="p">$</span>rm.site<span class="p">,</span> levels<span class="o">=</span>names<span class="p">(</span>remote.site.table<span class="p">))</span>
  df<span class="p">$</span>traffic.rate <span class="o">&lt;-</span> df<span class="p">$</span>traffic.rate<span class="o">/</span><span class="m">1</span>e6
  df
<span class="p">}</span>
pp <span class="o">&lt;-</span> <span class="s">&quot;/voip/modified.jitter.traffic.rate.database/&quot;</span>
<span class="k-Variable">F</span> <span class="o">&lt;-</span>  rhbiglm.stream.hdfs<span class="p">(</span>pp<span class="p">,</span>type<span class="o">=</span><span class="s">&#39;map&#39;</span><span class="p">,</span>modifier<span class="o">=</span>modifier<span class="p">,</span>batch<span class="o">=</span><span class="m">150</span><span class="p">,</span>quiet<span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
<span class="c1">## modifier is called for every list of &#39;batch&#39; key,value pairs</span>
<span class="c1">## the parameter df is a data frame (do.call(&quot;rbind&quot;,values))</span>
<span class="c1">## reset is FALSE when bigglm calls for more data</span>
<span class="c1">## and is TRUE when it requests the reader to go to the beginning of the stream</span>
b<span class="o">&lt;-</span>bigglm<span class="p">(</span>jitter~traffic.rate<span class="o">+</span>rm.site<span class="p">,</span>data<span class="o">=</span><span class="k-Variable">F</span><span class="p">,</span>maxit<span class="o">=</span><span class="m">3</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
</div>
<div class="section" id="mapreduce-administration">
<h2>MapReduce Administration<a class="headerlink" href="#mapreduce-administration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="rhex-submitting-a-mapreduce-r-object-to-hadoop">
<span id="index-9"></span><h3>rhex - Submitting a MapReduce R Object to Hadoop<a class="headerlink" href="#rhex-submitting-a-mapreduce-r-object-to-hadoop" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhex<span class="p">(</span>mrobj<span class="p">,</span> async<span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span>mapred<span class="p">)</span>
</pre></div>
</div>
<p>Submits a MapReduce job (created using <tt class="docutils literal"><span class="pre">rhmr</span></tt>) to the Hadoop MapReduce
framework. The argument <tt class="docutils literal"><span class="pre">mapred</span></tt> serves the same purpose as the <tt class="docutils literal"><span class="pre">mapred</span></tt>
argument to <tt class="docutils literal"><span class="pre">rhmr</span></tt>. This will override the settings in the object returned
from <tt class="docutils literal"><span class="pre">rhmr</span></tt>.  The function returns when the job ends (success/failure or
because the user terminated (see <tt class="docutils literal"><span class="pre">rhkill</span></tt>)). When <tt class="docutils literal"><span class="pre">async</span></tt> is TRUE, the
function returns immediately, leaving the job running in the background on Hadoop.</p>
<p>When <tt class="docutils literal"><span class="pre">async=TRUE</span></tt>, function returns an object of class <em>jobtoken</em>. The generic function
<tt class="docutils literal"><span class="pre">print.jobtoken</span></tt>, displays the start time, duration (in seconds) and percent
progress. This object can be used in calls to <tt class="docutils literal"><span class="pre">rhstatus</span></tt>,``rhjoin`` and <tt class="docutils literal"><span class="pre">rhkill</span></tt>.
Otherwise is returns a list of counters and the job state.</p>
</div>
<div class="section" id="rhstatus-monitoring-a-mapreduce-job">
<span id="index-10"></span><h3>rhstatus - Monitoring a MapReduce Job<a class="headerlink" href="#rhstatus-monitoring-a-mapreduce-job" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhstatus<span class="p">(</span>jobid<span class="p">,</span>mon.sec<span class="o">=</span><span class="m">0</span><span class="p">,</span> autokill<span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span>showErrors<span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span>verbose<span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
</pre></div>
</div>
<p>This returns the status of an running MapReduce job. The parameter <tt class="docutils literal"><span class="pre">jobid</span></tt> can
either be a string with the format <em>job_datetime_id</em>
(e.g. <em>job_201007281701_0274</em>) or the value returned from <tt class="docutils literal"><span class="pre">rhex</span></tt> with the
<tt class="docutils literal"><span class="pre">async</span></tt> option set to TRUE.</p>
<p>A list of 4 elements:</p>
<ul class="simple">
<li>the state of the job (one of <em>START, RUNNING, FAIL,COMPLETE</em>),</li>
<li>the duration in seconds,</li>
<li>a data frame with columns for the Map and Reduce phase. This data frame summarizes the number of tasks, the percent complete, and the number of tasks that are pending, running, complete or have failed.</li>
<li>In addition the list has an element that consists of both user defined and Hadoop MapReduce built in counters (counters can be user defined with a call to <tt class="docutils literal"><span class="pre">rhcounter</span></tt>).</li>
</ul>
<p>If <tt class="docutils literal"><span class="pre">mon.sec</span></tt> is greater than 0, a small data frame indicating the progress will be returned every <tt class="docutils literal"><span class="pre">mon.sec</span></tt> seconds.
If <tt class="docutils literal"><span class="pre">autokill</span></tt> is TRUE, then any R errors caused by the map/reduce code will cause the job to be killed. If <tt class="docutils literal"><span class="pre">verbose</span></tt> is TRUE, the above list
will be displayed too.</p>
</div>
<div class="section" id="rhjoin-waiting-on-completion-of-a-mapreduce-job">
<span id="index-11"></span><h3>rhjoin - Waiting on Completion of a MapReduce Job<a class="headerlink" href="#rhjoin-waiting-on-completion-of-a-mapreduce-job" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhjoin<span class="p">(</span>jobid<span class="p">,</span> ignore<span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
<p>Calling this functions pauses the R console till the MapReduce job indicated by
<tt class="docutils literal"><span class="pre">jobid</span></tt> is over (successfully or not). The parameter <tt class="docutils literal"><span class="pre">jobid</span></tt> can either be
string with the format <em>job_datetime_id</em> or the value returned from <tt class="docutils literal"><span class="pre">rhex</span></tt>
with the <tt class="docutils literal"><span class="pre">async</span></tt> option set to TRUE. This function returns the same object as
<tt class="docutils literal"><span class="pre">rhex</span></tt> i.e a list of the results of the job (TRUE or FALSE indicating success
or failure) and a counters returned by the job. If <tt class="docutils literal"><span class="pre">ignore</span></tt> is FALSE, the
progress will be displayed on the R console (much like <tt class="docutils literal"><span class="pre">rhex</span></tt>)</p>
</div>
<div class="section" id="rhkill-stopping-a-mapreduce-job">
<span id="index-12"></span><h3>rhkill - Stopping a MapReduce Job<a class="headerlink" href="#rhkill-stopping-a-mapreduce-job" title="Permalink to this headline">¶</a></h3>
<div class="highlight-r"><div class="highlight"><pre>rhkill<span class="p">(</span>jobid<span class="p">)</span>
</pre></div>
</div>
<p>This kills the MapReduce job with job identifier given by <tt class="docutils literal"><span class="pre">jobid</span></tt>. The
parameter <tt class="docutils literal"><span class="pre">jobid</span></tt> can either be string with the format <em>job_datetime_id</em> or
the value returned from  <tt class="docutils literal"><span class="pre">rhex</span></tt> with the <tt class="docutils literal"><span class="pre">async</span></tt> option set to
TRUE.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="mr.html" title="Packaging a Job for MapReduce"
             >next</a> |</li>
        <li class="right" >
          <a href="simulate.html" title="Simulations"
             >previous</a> |</li>
        <li><a href="index.html">RHIPE v0.65.3 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2010, Saptarshi Guha.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.0.7.
    </div>
  </body>
</html>